{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Originial Ochiai\n",
    "Script that runs the original Ochiai by running the real failing tests from the gzoltar execution. If the bug has no failing tests, it will be skipped. The output is a list with the Ochiai suspiciouness scores per method, one file per bug."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-14T14:24:39.017117Z",
     "start_time": "2023-08-14T14:24:39.013930Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from my_secrets import base_path\n",
    "\n",
    "\n",
    "paths_dict=  {\n",
    "    \"gzoltar_files_path\": os.path.join(base_path, \"DeepDiveBugReportsWithLogs\", \"data\", \"gzoltar_files\"),\n",
    "    \"output_file\": os.path.join(base_path, \"DeepDiveBugReportsWithLogs\", \"data\", \"ochiaiScores\", \"originalOchiai\"),\n",
    "    \"data_file_path\": os.path.join(base_path, \"DeepDiveBugReportsWithLogs\", \"data\", \"bug_reports_with_stack_traces_details.json\"),\n",
    "    \"failing_tests_info_file_name\": \"failing_tests_info\",\n",
    "    \"tests_analysis_results\":  os.path.join(base_path,\"DeepDiveBugReportsWithLogs\",  \"data\", \"rq1_results.json\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading the coverage data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%run ../utils.py\n",
    "\n",
    "bugs_data = json_file_to_dict(paths_dict[\"data_file_path\"])\n",
    "tests_analysis_results  = json_file_to_dict(paths_dict[\"tests_analysis_results\"])\n",
    "bugs = get_list_of_bugs_with_coverage(tests_analysis_results)\n",
    "coverage_data = {}\n",
    "for bug in bugs:\n",
    "    project, bug_id = bug.split(\"_\")\n",
    "    project_gzoltar_folder = os.path.join(paths_dict[\"gzoltar_files_path\"], project)\n",
    "    if not os.path.exists(project_gzoltar_folder):\n",
    "        print(\"Gzoltar folder not fount for the project \"+ project + \" Skipping!\")\n",
    "        continue\n",
    "    if not project in coverage_data.keys():\n",
    "        coverage_data[project] = {}\n",
    "    bug_gzoltar_folder = os.path.join(project_gzoltar_folder, bug_id)\n",
    "    if not os.path.exists(bug_gzoltar_folder):\n",
    "        print(\"Gzoltar folder not fount for the bugId \"+ bug + \" Skipping!\")\n",
    "        print(\"Skipping!!!!! \")\n",
    "        continue\n",
    "    coverage_data[project][bug_id] = {}\n",
    "    coverage_data[project][bug_id][\"statements_covered_per_test\"] = read_matrix_file(bug_gzoltar_folder)\n",
    "    print(\"Number of tests in bug \"+ project+ \"-\" + bug_id + \" - \" + str(len(coverage_data[project][bug_id][\"statements_covered_per_test\"])))\n",
    "    coverage_data[project][bug_id][\"lines_of_code_obj_list\"] = read_spectra_file(bug_gzoltar_folder)\n",
    "    test_names, test_results = read_tests_file(bug_gzoltar_folder)\n",
    "    coverage_data[project][bug_id][\"test_names\"] = test_names\n",
    "    coverage_data[project][bug_id][\"test_results\"] = test_results\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-14T14:24:40.116594Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the original Ochiai"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%run ../utils.py\n",
    "import math\n",
    "\n",
    "bugs_data = json_file_to_dict(paths_dict[\"data_file_path\"])\n",
    "failing_tests_info = {}\n",
    "\n",
    "for project in coverage_data.keys():\n",
    "    for bug_id in coverage_data[project].keys():\n",
    "        bug = project + \"_\"+ bug_id\n",
    "        print(bug)\n",
    "\n",
    "        bug_data = bugs_data[project][bug_id]\n",
    "        coverage = coverage_data[project][bug_id]\n",
    "\n",
    "        buggy_commit = bug_data[\"buggy_commit\"]\n",
    "        methods_list = []\n",
    "\n",
    "        failing_tests = []\n",
    "        for index, test in enumerate(coverage_data[project][bug_id][\"test_names\"]):\n",
    "            if not coverage_data[project][bug_id][\"test_results\"][index]: # failing test\n",
    "                failing_tests.append(test)\n",
    "        failing_tests = list(set(failing_tests))\n",
    "\n",
    "        if not failing_tests:\n",
    "            print(f\"The bug {project}_{bug_id} does not contain failing tests. Skipping it\")\n",
    "            continue\n",
    "\n",
    "        print(\"* Part 1 - Modifying the Gzoltar results to be per method instead of statement\")\n",
    "        coverage[\"methods_covered_per_test\"] = []\n",
    "        coverage[\"methods_obj_list\"] = []\n",
    "        method_to_pos = {}\n",
    "\n",
    "        #Getting the methods list\n",
    "        for index_t, test_coverage in enumerate(coverage[\"statements_covered_per_test\"]):\n",
    "            for index_s, statement_instance in enumerate(coverage[\"statements_covered_per_test\"][index_t]):\n",
    "                lines_of_code_obj_list = coverage[\"lines_of_code_obj_list\"][index_s]\n",
    "                method_id =  lines_of_code_obj_list[\"class_name\"].replace(\"$\", \".\") + \"#\" + lines_of_code_obj_list[\"method_name\"]\n",
    "                if method_id not in method_to_pos:\n",
    "                    method_to_pos[method_id] = len(coverage[\"methods_obj_list\"])\n",
    "                    coverage[\"methods_obj_list\"].append(method_id)\n",
    "\n",
    "\n",
    "        # Getting the methods coverage matrix\n",
    "        for index_t, test_coverage in enumerate(coverage[\"statements_covered_per_test\"]):\n",
    "            test_name = coverage[\"test_names\"][index_t]\n",
    "            # Pre=populating the matrix\n",
    "            coverage[\"methods_covered_per_test\"].append([])\n",
    "            for method_name in coverage[\"methods_obj_list\"]:\n",
    "                coverage[\"methods_covered_per_test\"][index_t].append(\"0\")\n",
    "            # Getting the coverage\n",
    "            for index_s, statement_instance in enumerate(coverage[\"statements_covered_per_test\"][index_t]):\n",
    "                lines_of_code_obj_list = coverage[\"lines_of_code_obj_list\"][index_s]\n",
    "                method_id =  lines_of_code_obj_list[\"class_name\"].replace(\"$\", \".\") + \"#\" + lines_of_code_obj_list[\"method_name\"]\n",
    "                position = method_to_pos[method_id]\n",
    "                if coverage[\"methods_covered_per_test\"][index_t][position]!= \"1\":\n",
    "                    coverage[\"methods_covered_per_test\"][index_t][position] = statement_instance\n",
    "        print(\"Storing the gzoltar results extended per method in a file for future uses\")\n",
    "        store_methods_coverage_in_file(coverage, project, bug_id, paths_dict[\"gzoltar_files_path\"], \"test_results_original_ochiai.csv\")\n",
    "        print(\"store_methods_coverage_in_file operation completed\")\n",
    "\n",
    "        print(\"* Part 2 - Executing Ochiai\")\n",
    "        methods_ochiai_scores = {}\n",
    "        for index_m, method_name in enumerate(coverage[\"methods_obj_list\"]):\n",
    "            n00 = 0\n",
    "            n01 = 0\n",
    "            n10 = 0\n",
    "            n11 = 0\n",
    "            s_o = 0\n",
    "            for index_t, test_name in enumerate(coverage[\"test_names\"]):\n",
    "                if str(coverage[\"methods_covered_per_test\"][index_t][index_m]) == \"1\":\n",
    "                    if not coverage[\"test_results\"][index_t]:\n",
    "                        n11 += 1\n",
    "                    else:\n",
    "                        n10 += 1\n",
    "                else:\n",
    "                    if not coverage[\"test_results\"][index_t]:\n",
    "                        n01 += 1\n",
    "                    else:\n",
    "                        n00 += 1\n",
    "            try:\n",
    "                s_o = n11/math.sqrt((n11+n01)*(n11+n10))\n",
    "            except ZeroDivisionError:\n",
    "                s_o = 0\n",
    "            methods_ochiai_scores[method_name] = s_o\n",
    "\n",
    "        if project not in failing_tests_info.keys():\n",
    "            failing_tests_info[project] = {}\n",
    "\n",
    "        failing_tests_info[project][bug_id] = {}\n",
    "        failing_tests_info[project][bug_id][\"passing_tests_number\"] = len(coverage[\"test_results\"]) - len(failing_tests_info)\n",
    "        failing_tests_info[project][bug_id][\"failing_tests_number\"] = len(failing_tests)\n",
    "\n",
    "        print(\"Number of passing tests: \" + str(failing_tests_info[project][bug_id][\"passing_tests_number\"]))\n",
    "        print(\"Number of failing tests: \" + str(failing_tests_info[project][bug_id][\"failing_tests_number\"]) + \"\\n\")\n",
    "        dict_to_json_file(os.path.join(paths_dict[\"output_file\"], project, bug_id), methods_ochiai_scores)\n",
    "\n",
    "dict_to_json_file(os.path.join(paths_dict[\"output_file\"],\n",
    "                               paths_dict[\"failing_tests_info_file_name\"]), failing_tests_info)\n",
    "print(\"Execution completed\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
